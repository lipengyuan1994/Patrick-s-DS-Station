{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Patrick ğŸŒ°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18846\n",
      "From: qureshi@bmerh185.bnr.ca (Emran Qureshi)\n",
      "Subject: Re: Europe vs. Muslim Bosnians\n",
      "Organization: Bell-Northern Research, Ottawa, Canada\n",
      "Lines: 26\n",
      "\n",
      "In article <C6x81M.EJF@news.cis.umn.edu> prabhak@giga.cs.umn.edu (Satya Prabhakar) writes:\n",
      ">(mohamed.s.sadek) writes:\n",
      ">>\n",
      ">>I like what Mr. Joseph Biden had to say yesterday 5/11/93 in the senate.\n",
      ">>\n",
      ">>Condemening the european lack of action and lack of support to us plans \n",
      ">>and calling that \"moral rape\".\n",
      ">>\n",
      ">>He went on to say that the reason for that is \"out right religious BIGOTRY\"\n",
      ">\n",
      ">Actually, this strife in Yugoslavia goes back a long way. Bosinan Muslims,\n",
      ">in collaboration with the Nazis, did to Serbians after the first world\n",
      ">war what Serbs are doing to Muslims now. This is not a fresh case of\n",
      ">ethnic cleansing but just another chapter in the continuing saga\n",
      ">of intense mutual hatred, destruction,... Not taking sides in this\n",
      ">perpetual war does not amount to religious bigotry. It could just\n",
      ">be helplessness with regards to bringing peace to a region that does\n",
      ">not even know the meaning of the word.\n",
      ">\n",
      ">Satya Prabhakar\n",
      ">--\n",
      "\n",
      "Yeah right, sorta like the Indian sub-contient, eh?\n",
      "\n",
      "Regards,\n",
      "Emran\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ä»sklearn.datasetsé‡Œå¯¼å…¥æ–°é—»æ•°æ®æŠ“å–å™¨fetch_20newsgroupsã€‚\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "# ä¸ä¹‹å‰é¢„å­˜çš„æ•°æ®ä¸åŒï¼Œfetch_20newsgroupséœ€è¦å³æ—¶ä»äº’è”ç½‘ä¸‹è½½æ•°æ®ã€‚\n",
    "news = fetch_20newsgroups(subset='all')\n",
    "# æŸ¥éªŒæ•°æ®è§„æ¨¡å’Œç»†èŠ‚ã€‚\n",
    "print( len(news.data))\n",
    "print( news.data[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä»sklearn.model_selection å¯¼å…¥ train_test_splitã€‚\n",
    "from sklearn.model_selection import train_test_split\n",
    "# éšæœºé‡‡æ ·25%çš„æ•°æ®æ ·æœ¬ä½œä¸ºæµ‹è¯•é›†ã€‚\n",
    "X_train, X_test, y_train, y_test = train_test_split(news.data, news.target, test_size=0.25, random_state=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä»sklearn.feature_extraction.texté‡Œå¯¼å…¥ç”¨äºæ–‡æœ¬ç‰¹å¾å‘é‡è½¬åŒ–æ¨¡å—ã€‚è¯¦ç»†ä»‹ç»è¯·è¯»è€…å‚è€ƒ3.1.1.1 ç‰¹å¾æŠ½å–ä¸€èŠ‚ã€‚\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vec = CountVectorizer()\n",
    "X_train = vec.fit_transform(X_train)\n",
    "X_test = vec.transform(X_test)\n",
    "\n",
    "# ä»sklearn.naive_bayesé‡Œå¯¼å…¥æœ´ç´ è´å¶æ–¯æ¨¡å‹ã€‚\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# ä»ä½¿ç”¨é»˜è®¤é…ç½®åˆå§‹åŒ–æœ´ç´ è´å¶æ–¯æ¨¡å‹ã€‚\n",
    "mnb = MultinomialNB()\n",
    "# åˆ©ç”¨è®­ç»ƒæ•°æ®å¯¹æ¨¡å‹å‚æ•°è¿›è¡Œä¼°è®¡ã€‚\n",
    "mnb.fit(X_train, y_train)\n",
    "# å¯¹æµ‹è¯•æ ·æœ¬è¿›è¡Œç±»åˆ«é¢„æµ‹ï¼Œç»“æœå­˜å‚¨åœ¨å˜é‡y_predictä¸­ã€‚\n",
    "y_predict = mnb.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of Naive Bayes Classifier is 0.8397707979626485\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.86      0.86      0.86       201\n",
      "           comp.graphics       0.59      0.86      0.70       250\n",
      " comp.os.ms-windows.misc       0.89      0.10      0.17       248\n",
      "comp.sys.ibm.pc.hardware       0.60      0.88      0.72       240\n",
      "   comp.sys.mac.hardware       0.93      0.78      0.85       242\n",
      "          comp.windows.x       0.82      0.84      0.83       263\n",
      "            misc.forsale       0.91      0.70      0.79       257\n",
      "               rec.autos       0.89      0.89      0.89       238\n",
      "         rec.motorcycles       0.98      0.92      0.95       276\n",
      "      rec.sport.baseball       0.98      0.91      0.95       251\n",
      "        rec.sport.hockey       0.93      0.99      0.96       233\n",
      "               sci.crypt       0.86      0.98      0.91       238\n",
      "         sci.electronics       0.85      0.88      0.86       249\n",
      "                 sci.med       0.92      0.94      0.93       245\n",
      "               sci.space       0.89      0.96      0.92       221\n",
      "  soc.religion.christian       0.78      0.96      0.86       232\n",
      "      talk.politics.guns       0.88      0.96      0.92       251\n",
      "   talk.politics.mideast       0.90      0.98      0.94       231\n",
      "      talk.politics.misc       0.79      0.89      0.84       188\n",
      "      talk.religion.misc       0.93      0.44      0.60       158\n",
      "\n",
      "               micro avg       0.84      0.84      0.84      4712\n",
      "               macro avg       0.86      0.84      0.82      4712\n",
      "            weighted avg       0.86      0.84      0.82      4712\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ä»sklearn.metricsé‡Œå¯¼å…¥classification_reportç”¨äºè¯¦ç»†çš„åˆ†ç±»æ€§èƒ½æŠ¥å‘Šã€‚\n",
    "from sklearn.metrics import classification_report\n",
    "print ('The accuracy of Naive Bayes Classifier is', mnb.score(X_test, y_test))\n",
    "print (classification_report(y_test, y_predict, target_names = news.target_names))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "* æœ´ç´ è´å¶æ–¯æ¨¡å‹è¢«å¹¿æ³›åº”ç”¨äºæµ·é‡äº’è”ç½‘æ–‡æœ¬åˆ†ç±»ä»»åŠ¡ã€‚ç”±äºå…¶è¾ƒå¼ºçš„ç‰¹å¾æ¡ä»¶ç‹¬ç«‹å‡è®¾ï¼Œä½¿å¾—æ¨¡å‹é¢„æµ‹æ‰€éœ€è¦ä¼°è®¡çš„å‚æ•°è§„æ¨¡ä»å¹‚æŒ‡æ•°é‡çº§å‘çº¿æ€§é‡çº§å‡å°‘ï¼Œæå¤§åœ°èŠ‚çº¦äº†å†…å­˜æ¶ˆè€—å’Œè®¡ç®—æ—¶é—´ã€‚ä½†æ˜¯ï¼Œä¹Ÿæ­£æ˜¯å—è¿™ç§å¼ºå‡è®¾çš„é™åˆ¶ï¼Œæ¨¡å‹è®­ç»ƒæ—¶æ— æ³•å°†å„ä¸ªç‰¹å¾ä¹‹é—´çš„è”ç³»è€ƒé‡åœ¨å†…ï¼Œä½¿å¾—è¯¥æ¨¡å‹åœ¨å…¶ä»–æ•°æ®ç‰¹å¾å…³è”æ€§è¾ƒå¼ºçš„åˆ†ç±»ä»»åŠ¡ä¸Šçš„æ€§èƒ½è¡¨ç°ä¸ä½³ã€‚\n",
    "* The naive Bayesian model is widely used in massive Internet text classification tasks. Due to its strong independent assumption of feature conditions, the estimated parameter size required for model prediction is reduced from the power index to the linear magnitude, which greatly saves memory consumption and computation time. However, it is also limited by this strong hypothesis that the model can't consider the connection between each feature during the training, which makes the model perform poorly on other classification tasks with strong data feature relevance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
