{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color= 'purple'>\n",
    "\n",
    "# Feature Extraction \n",
    "Patrick ğŸŒ°\n",
    "* DicVectorizer extract feature from dictionary\n",
    "* CountVectorizer VS. TfidfVectorizer\n",
    "* Remove stop words VS. unremove stop words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DicVectorizer å¯¹ä½¿ç”¨å­—å…¸å­˜å‚¨çš„æ•°æ®è¿›è¡Œç‰¹å¾æŠ½å–ä¸å‘é‡åŒ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  0.  0. 33.]\n",
      " [ 0.  1.  0. 12.]\n",
      " [ 0.  0.  1. 18.]]\n",
      "['city=Dubai', 'city=London', 'city=San Fransisco', 'temperature']\n"
     ]
    }
   ],
   "source": [
    "# å®šä¹‰ä¸€ç»„å­—å…¸åˆ—è¡¨ï¼Œç”¨æ¥è¡¨ç¤ºå¤šä¸ªæ•°æ®æ ·æœ¬ï¼ˆæ¯ä¸ªå­—å…¸ä»£è¡¨ä¸€ä¸ªæ•°æ®æ ·æœ¬ï¼‰ã€‚\n",
    "measurements = [{'city': 'Dubai', 'temperature': 33.}, {'city': 'London', 'temperature': 12.}, {'city': 'San Fransisco', 'temperature': 18.}]\n",
    "# ä»sklearn.feature_extraction å¯¼å…¥ DictVectorizer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "# åˆå§‹åŒ–DictVectorizerç‰¹å¾æŠ½å–å™¨\n",
    "vec = DictVectorizer()\n",
    "# è¾“å‡ºè½¬åŒ–ä¹‹åçš„ç‰¹å¾çŸ©é˜µã€‚\n",
    "print (vec.fit_transform(measurements).toarray())\n",
    "# è¾“å‡ºå„ä¸ªç»´åº¦çš„ç‰¹å¾å«ä¹‰ã€‚\n",
    "print (vec.get_feature_names())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ä½¿ç”¨CountVectorizer åœ¨ä¸å»æ‰stop wordæ¡ä»¶ä¸‹ï¼Œå¯¹æ–‡æœ¬ç‰¹å¾è¿›è¡Œé‡åŒ–çš„æœ´ç´ è´å¶æ–¯åˆ†ç±»æ€§èƒ½æµ‹è¯•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of classifying 20newsgroups using Naive Bayes (CountVectorizer without filtering stopwords): 0.8397707979626485\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.86      0.86      0.86       201\n",
      "           comp.graphics       0.59      0.86      0.70       250\n",
      " comp.os.ms-windows.misc       0.89      0.10      0.17       248\n",
      "comp.sys.ibm.pc.hardware       0.60      0.88      0.72       240\n",
      "   comp.sys.mac.hardware       0.93      0.78      0.85       242\n",
      "          comp.windows.x       0.82      0.84      0.83       263\n",
      "            misc.forsale       0.91      0.70      0.79       257\n",
      "               rec.autos       0.89      0.89      0.89       238\n",
      "         rec.motorcycles       0.98      0.92      0.95       276\n",
      "      rec.sport.baseball       0.98      0.91      0.95       251\n",
      "        rec.sport.hockey       0.93      0.99      0.96       233\n",
      "               sci.crypt       0.86      0.98      0.91       238\n",
      "         sci.electronics       0.85      0.88      0.86       249\n",
      "                 sci.med       0.92      0.94      0.93       245\n",
      "               sci.space       0.89      0.96      0.92       221\n",
      "  soc.religion.christian       0.78      0.96      0.86       232\n",
      "      talk.politics.guns       0.88      0.96      0.92       251\n",
      "   talk.politics.mideast       0.90      0.98      0.94       231\n",
      "      talk.politics.misc       0.79      0.89      0.84       188\n",
      "      talk.religion.misc       0.93      0.44      0.60       158\n",
      "\n",
      "               micro avg       0.84      0.84      0.84      4712\n",
      "               macro avg       0.86      0.84      0.82      4712\n",
      "            weighted avg       0.86      0.84      0.82      4712\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ä»sklearn.datasetsé‡Œå¯¼å…¥20ç±»æ–°é—»æ–‡æœ¬æ•°æ®æŠ“å–å™¨ã€‚\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "# ä»äº’è”ç½‘ä¸Šå³æ—¶ä¸‹è½½æ–°é—»æ ·æœ¬,subset='all'å‚æ•°ä»£è¡¨ä¸‹è½½å…¨éƒ¨è¿‘2ä¸‡æ¡æ–‡æœ¬å­˜å‚¨åœ¨å˜é‡newsä¸­ã€‚\n",
    "news = fetch_20newsgroups(subset='all')\n",
    "\n",
    "# ä»sklearn.model_selectionå¯¼å…¥train_test_splitæ¨¡å—ç”¨äºåˆ†å‰²æ•°æ®é›†ã€‚\n",
    "from sklearn.model_selection import train_test_split\n",
    "# å¯¹newsä¸­çš„æ•°æ®dataè¿›è¡Œåˆ†å‰²ï¼Œ25%çš„æ–‡æœ¬ç”¨ä½œæµ‹è¯•é›†ï¼›75%ä½œä¸ºè®­ç»ƒé›†ã€‚\n",
    "X_train, X_test, y_train, y_test = train_test_split(news.data, news.target, test_size=0.25, random_state=33)\n",
    "\n",
    "# ä»sklearn.feature_extraction.texté‡Œå¯¼å…¥CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# é‡‡ç”¨é»˜è®¤çš„é…ç½®å¯¹CountVectorizerè¿›è¡Œåˆå§‹åŒ–ï¼ˆé»˜è®¤é…ç½®ä¸å»é™¤è‹±æ–‡åœç”¨è¯ï¼‰ï¼Œå¹¶ä¸”èµ‹å€¼ç»™å˜é‡count_vecã€‚\n",
    "count_vec = CountVectorizer()\n",
    "\n",
    "# åªä½¿ç”¨è¯é¢‘ç»Ÿè®¡çš„æ–¹å¼å°†åŸå§‹è®­ç»ƒå’Œæµ‹è¯•æ–‡æœ¬è½¬åŒ–ä¸ºç‰¹å¾å‘é‡ã€‚\n",
    "X_count_train = count_vec.fit_transform(X_train)\n",
    "X_count_test = count_vec.transform(X_test)\n",
    "\n",
    "# ä»sklearn.naive_bayesé‡Œå¯¼å…¥æœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨ã€‚\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "# ä½¿ç”¨é»˜è®¤çš„é…ç½®å¯¹åˆ†ç±»å™¨è¿›è¡Œåˆå§‹åŒ–ã€‚\n",
    "mnb_count = MultinomialNB()\n",
    "# ä½¿ç”¨æœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨ï¼Œå¯¹CountVectorizerï¼ˆä¸å»é™¤åœç”¨è¯ï¼‰åçš„è®­ç»ƒæ ·æœ¬è¿›è¡Œå‚æ•°å­¦ä¹ ã€‚\n",
    "mnb_count.fit(X_count_train, y_train)\n",
    "\n",
    "# è¾“å‡ºæ¨¡å‹å‡†ç¡®æ€§ç»“æœã€‚\n",
    "print ('The accuracy of classifying 20newsgroups using Naive Bayes (CountVectorizer without filtering stopwords):', mnb_count.score(X_count_test, y_test))\n",
    "# å°†åˆ†ç±»é¢„æµ‹çš„ç»“æœå­˜å‚¨åœ¨å˜é‡y_count_predictä¸­ã€‚\n",
    "y_count_predict = mnb_count.predict(X_count_test)\n",
    "# ä»sklearn.metrics å¯¼å…¥ classification_reportã€‚\n",
    "from sklearn.metrics import classification_report\n",
    "# è¾“å‡ºæ›´åŠ è¯¦ç»†çš„å…¶ä»–è¯„ä»·åˆ†ç±»æ€§èƒ½çš„æŒ‡æ ‡ã€‚\n",
    "print (classification_report(y_test, y_count_predict, target_names = news.target_names))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ä½¿ç”¨TfidfVectorizer ä¸å»æ‰stop wordæ¡ä»¶ä¸‹ï¼Œå¯¹æ–‡æœ¬è¿›è¡Œé‡åŒ–çš„naive bayes åˆ†ç±»æ€§èƒ½æµ‹è¯•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of classifying 20newsgroups with Naive Bayes (TfidfVectorizer without filtering stopwords): 0.8463497453310697\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.84      0.67      0.75       201\n",
      "           comp.graphics       0.85      0.74      0.79       250\n",
      " comp.os.ms-windows.misc       0.82      0.85      0.83       248\n",
      "comp.sys.ibm.pc.hardware       0.76      0.88      0.82       240\n",
      "   comp.sys.mac.hardware       0.94      0.84      0.89       242\n",
      "          comp.windows.x       0.96      0.84      0.89       263\n",
      "            misc.forsale       0.93      0.69      0.79       257\n",
      "               rec.autos       0.84      0.92      0.88       238\n",
      "         rec.motorcycles       0.98      0.92      0.95       276\n",
      "      rec.sport.baseball       0.96      0.91      0.94       251\n",
      "        rec.sport.hockey       0.88      0.99      0.93       233\n",
      "               sci.crypt       0.73      0.98      0.83       238\n",
      "         sci.electronics       0.91      0.83      0.87       249\n",
      "                 sci.med       0.97      0.92      0.95       245\n",
      "               sci.space       0.89      0.96      0.93       221\n",
      "  soc.religion.christian       0.51      0.97      0.67       232\n",
      "      talk.politics.guns       0.83      0.96      0.89       251\n",
      "   talk.politics.mideast       0.92      0.97      0.95       231\n",
      "      talk.politics.misc       0.98      0.62      0.76       188\n",
      "      talk.religion.misc       0.93      0.16      0.28       158\n",
      "\n",
      "               micro avg       0.85      0.85      0.85      4712\n",
      "               macro avg       0.87      0.83      0.83      4712\n",
      "            weighted avg       0.87      0.85      0.84      4712\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ä»sklearn.feature_extraction.texté‡Œåˆ†åˆ«å¯¼å…¥TfidfVectorizerã€‚\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# é‡‡ç”¨é»˜è®¤çš„é…ç½®å¯¹TfidfVectorizerè¿›è¡Œåˆå§‹åŒ–ï¼ˆé»˜è®¤é…ç½®ä¸å»é™¤è‹±æ–‡åœç”¨è¯ï¼‰ï¼Œå¹¶ä¸”èµ‹å€¼ç»™å˜é‡tfidf_vecã€‚\n",
    "tfidf_vec = TfidfVectorizer()\n",
    "\n",
    "# ä½¿ç”¨tfidfçš„æ–¹å¼ï¼Œå°†åŸå§‹è®­ç»ƒå’Œæµ‹è¯•æ–‡æœ¬è½¬åŒ–ä¸ºç‰¹å¾å‘é‡ã€‚\n",
    "X_tfidf_train = tfidf_vec.fit_transform(X_train)\n",
    "X_tfidf_test = tfidf_vec.transform(X_test)\n",
    "\n",
    "# ä¾ç„¶ä½¿ç”¨é»˜è®¤é…ç½®çš„æœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨ï¼Œåœ¨ç›¸åŒçš„è®­ç»ƒå’Œæµ‹è¯•æ•°æ®ä¸Šï¼Œå¯¹æ–°çš„ç‰¹å¾é‡åŒ–æ–¹å¼è¿›è¡Œæ€§èƒ½è¯„ä¼°ã€‚\n",
    "mnb_tfidf = MultinomialNB()\n",
    "mnb_tfidf.fit(X_tfidf_train, y_train)\n",
    "print ('The accuracy of classifying 20newsgroups with Naive Bayes (TfidfVectorizer without filtering stopwords):', mnb_tfidf.score(X_tfidf_test, y_test))\n",
    "y_tfidf_predict = mnb_tfidf.predict(X_tfidf_test)\n",
    "print (classification_report(y_test, y_tfidf_predict, target_names = news.target_names))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color= 'red'>\n",
    "    \n",
    "* åœ¨ä¸å»æ‰stop wordçš„æ¡ä»¶ä¸‹ï¼Œä½¿ç”¨TfidVectorizerå¯¹è®­ç»ƒå’Œæµ‹è¯•æ–‡æœ¬è¿›è¡Œé‡åŒ–ï¼Œå¹¶åˆ©ç”¨é»˜è®¤é…ç½®çš„æœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨ï¼Œåœ¨æµ‹è¯•æ–‡æœ¬ä¸Šå¯ä»¥å¾—åˆ°æ¯”CountVectorizeræ›´é«˜çš„é¢„æµ‹å‡†ç¡®æ€§ã€‚ \n",
    "* åœ¨è®­ç»ƒæ–‡æœ¬é‡è¾ƒå¤šçš„æ—¶å€™ï¼Œåˆ©ç”¨TfidfVectorizerå‹åˆ¶è¿™äº›å¸¸ç”¨è¯æ±‡çš„å¯¹åˆ†ç±»å™¨çš„å¹²æ‰°ï¼Œå¾€å¾€å¯ä»¥èµ·åˆ°æå‡æ¨¡å‹æ€§èƒ½çš„ä½œç”¨ã€‚\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### åˆ†åˆ«ä½¿ç”¨CountVectorizer å’Œ TfidfVectorizeråœ¨å»æ‰stop wordçš„æ¡ä»¶ä¸‹ï¼Œå¯¹æ–‡æœ¬ç‰¹å¾è¿›è¡Œé‡åŒ–çš„æœ´ç´ è´å¶æ–¯åˆ†ç±»æ€§èƒ½æµ‹è¯•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of classifying 20newsgroups using Naive Bayes (CountVectorizer by filtering stopwords): 0.8637521222410866\n",
      "The accuracy of classifying 20newsgroups with Naive Bayes (TfidfVectorizer by filtering stopwords): 0.8826400679117148\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.85      0.89      0.87       201\n",
      "           comp.graphics       0.62      0.88      0.73       250\n",
      " comp.os.ms-windows.misc       0.93      0.22      0.36       248\n",
      "comp.sys.ibm.pc.hardware       0.62      0.88      0.73       240\n",
      "   comp.sys.mac.hardware       0.93      0.85      0.89       242\n",
      "          comp.windows.x       0.82      0.85      0.84       263\n",
      "            misc.forsale       0.90      0.79      0.84       257\n",
      "               rec.autos       0.91      0.91      0.91       238\n",
      "         rec.motorcycles       0.98      0.94      0.96       276\n",
      "      rec.sport.baseball       0.98      0.92      0.95       251\n",
      "        rec.sport.hockey       0.92      0.99      0.95       233\n",
      "               sci.crypt       0.91      0.97      0.93       238\n",
      "         sci.electronics       0.87      0.89      0.88       249\n",
      "                 sci.med       0.94      0.95      0.95       245\n",
      "               sci.space       0.91      0.96      0.93       221\n",
      "  soc.religion.christian       0.87      0.94      0.90       232\n",
      "      talk.politics.guns       0.89      0.96      0.93       251\n",
      "   talk.politics.mideast       0.95      0.98      0.97       231\n",
      "      talk.politics.misc       0.84      0.90      0.87       188\n",
      "      talk.religion.misc       0.91      0.53      0.67       158\n",
      "\n",
      "               micro avg       0.86      0.86      0.86      4712\n",
      "               macro avg       0.88      0.86      0.85      4712\n",
      "            weighted avg       0.88      0.86      0.85      4712\n",
      "\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.86      0.81      0.83       201\n",
      "           comp.graphics       0.85      0.81      0.83       250\n",
      " comp.os.ms-windows.misc       0.84      0.87      0.86       248\n",
      "comp.sys.ibm.pc.hardware       0.78      0.88      0.83       240\n",
      "   comp.sys.mac.hardware       0.92      0.90      0.91       242\n",
      "          comp.windows.x       0.95      0.88      0.91       263\n",
      "            misc.forsale       0.90      0.80      0.85       257\n",
      "               rec.autos       0.89      0.92      0.90       238\n",
      "         rec.motorcycles       0.98      0.94      0.96       276\n",
      "      rec.sport.baseball       0.97      0.93      0.95       251\n",
      "        rec.sport.hockey       0.88      0.99      0.93       233\n",
      "               sci.crypt       0.85      0.98      0.91       238\n",
      "         sci.electronics       0.93      0.86      0.89       249\n",
      "                 sci.med       0.96      0.93      0.95       245\n",
      "               sci.space       0.90      0.97      0.93       221\n",
      "  soc.religion.christian       0.70      0.96      0.81       232\n",
      "      talk.politics.guns       0.84      0.98      0.90       251\n",
      "   talk.politics.mideast       0.92      0.99      0.95       231\n",
      "      talk.politics.misc       0.97      0.74      0.84       188\n",
      "      talk.religion.misc       0.96      0.29      0.45       158\n",
      "\n",
      "               micro avg       0.88      0.88      0.88      4712\n",
      "               macro avg       0.89      0.87      0.87      4712\n",
      "            weighted avg       0.89      0.88      0.88      4712\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ç»§ç»­æ²¿ç”¨ä»£ç 56ä¸ä»£ç 57ä¸­å¯¼å…¥çš„å·¥å…·åŒ…ï¼ˆåœ¨åŒä¸€ä»½æºä»£ç ä¸­ï¼Œæˆ–è€…ä¸å…³é—­è§£é‡Šå™¨ç¯å¢ƒï¼‰ï¼Œåˆ†åˆ«ä½¿ç”¨åœç”¨è¯è¿‡æ»¤é…ç½®åˆå§‹åŒ–CountVectorizerä¸TfidfVectorizerã€‚\n",
    "count_filter_vec, tfidf_filter_vec = CountVectorizer(analyzer='word', stop_words='english'), TfidfVectorizer(analyzer='word', stop_words='english')\n",
    "\n",
    "# ä½¿ç”¨å¸¦æœ‰åœç”¨è¯è¿‡æ»¤çš„CountVectorizerå¯¹è®­ç»ƒå’Œæµ‹è¯•æ–‡æœ¬åˆ†åˆ«è¿›è¡Œé‡åŒ–å¤„ç†ã€‚\n",
    "X_count_filter_train = count_filter_vec.fit_transform(X_train)\n",
    "X_count_filter_test = count_filter_vec.transform(X_test)\n",
    "\n",
    "# ä½¿ç”¨å¸¦æœ‰åœç”¨è¯è¿‡æ»¤çš„TfidfVectorizerå¯¹è®­ç»ƒå’Œæµ‹è¯•æ–‡æœ¬åˆ†åˆ«è¿›è¡Œé‡åŒ–å¤„ç†ã€‚\n",
    "X_tfidf_filter_train = tfidf_filter_vec.fit_transform(X_train)\n",
    "X_tfidf_filter_test = tfidf_filter_vec.transform(X_test)\n",
    "\n",
    "# åˆå§‹åŒ–é»˜è®¤é…ç½®çš„æœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨ï¼Œå¹¶å¯¹CountVectorizeråçš„æ•°æ®è¿›è¡Œé¢„æµ‹ä¸å‡†ç¡®æ€§è¯„ä¼°ã€‚\n",
    "mnb_count_filter = MultinomialNB()\n",
    "mnb_count_filter.fit(X_count_filter_train, y_train)\n",
    "print ('The accuracy of classifying 20newsgroups using Naive Bayes (CountVectorizer by filtering stopwords):', mnb_count_filter.score(X_count_filter_test, y_test))\n",
    "y_count_filter_predict = mnb_count_filter.predict(X_count_filter_test)\n",
    "\n",
    "# åˆå§‹åŒ–å¦ä¸€ä¸ªé»˜è®¤é…ç½®çš„æœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨ï¼Œå¹¶å¯¹TfidfVectorizeråçš„æ•°æ®è¿›è¡Œé¢„æµ‹ä¸å‡†ç¡®æ€§è¯„ä¼°ã€‚\n",
    "mnb_tfidf_filter = MultinomialNB()\n",
    "mnb_tfidf_filter.fit(X_tfidf_filter_train, y_train)\n",
    "print ('The accuracy of classifying 20newsgroups with Naive Bayes (TfidfVectorizer by filtering stopwords):', mnb_tfidf_filter.score(X_tfidf_filter_test, y_test))\n",
    "y_tfidf_filter_predict = mnb_tfidf_filter.predict(X_tfidf_filter_test)\n",
    "\n",
    "# å¯¹ä¸Šè¿°ä¸¤ä¸ªæ¨¡å‹è¿›è¡Œæ›´åŠ è¯¦ç»†çš„æ€§èƒ½è¯„ä¼°ã€‚\n",
    "from sklearn.metrics import classification_report\n",
    "print (classification_report(y_test, y_count_filter_predict, target_names = news.target_names))\n",
    "print( classification_report(y_test, y_tfidf_filter_predict, target_names = news.target_names))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<font color= 'red'>\n",
    "\n",
    "* ä¾æ—§è¯æ˜TfidfVectorizerçš„ç‰¹å¾æŠ½å–å’Œé‡åŒ–æ–¹æ³•æ›´åŠ å…·æœ‰ä¼˜åŠ¿\n",
    "* å¯¹stop wordè¿›è¡Œè¿‡æ»¤çš„æ–‡æœ¬ç‰¹å¾æŠ½å–æ–¹æ³•ï¼Œå¹³å‡æ¯”ä¸åœç”¨stop wordçš„æ¨¡å‹ç»¼åˆæ€§èƒ½æé«˜ 3%-4%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
