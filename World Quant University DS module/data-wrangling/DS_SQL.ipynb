{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "%logstop\n",
    "%logstart -rtq ~/.logs/DS_SQL.py append\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "matplotlib.rcParams['figure.dpi'] = 144"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structured Query Language (SQL)\n",
    "<!-- requirement: data/customers.csv -->\n",
    "<!-- requirement: data/products.csv -->\n",
    "<!-- requirement: data/orders.csv -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SQL is one of the most common computer languages in use for working with data today. It is a standardized language for accessing and manipulating relational databases. While it is relatively limited compared to a general programming language such as Python, it is highly optimized for efficient retrieval and aggregation of data from database tables. Its broad support and use virtually guarantees that any professional data scientist or analyst will encounter SQL eventually. Furthermore, SQL is often the paradigm used to discuss the relational data model, which has implications that apply beyond SQL compliant databases.\n",
    "\n",
    "We will explore SQL from within Python, which will allow us to work with SQL in a familiar setting and also see opportunities for compatibility between the world of relational databases and data science tools within Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relational data model\n",
    "\n",
    "The relational data model for the most part corresponds with our intuitive notion of a table. Each row is a **relation**, usually representing some object, event, or idea. Each column corresponds with an **attribute** which characterizes the relation. In order to reduce redundancy in a database, when creating at able we typically include the minimum amount of attributes required to fully define a relation. This (admittedly vague) guideline is formalized in the idea of [database normalization](https://en.wikipedia.org/wiki/Database_normalization).\n",
    "\n",
    "For example, considering the following table representing orders from an online retailer.\n",
    "\n",
    "\n",
    "Customer | ID | Order ID | Product ID | Price | Delivery Address | Billing Address\n",
    ":-------:|:--:|:--------:|:----------:|:-----:|:----------------:|:---------------:\n",
    "   Omar  | 435|   62353  |    103     |  6.95 |  ***** Munich, Germany | ***** Berlin, Germany |\n",
    "   Omar  | 435|   62353  |    4028    |  35.50|  ***** Tunis, Tunisia  | ***** Berlin, Germany |\n",
    "  Stuart |5692|   64598  |    103     |  6.95 |  ***** Dover, UK | ***** Dover, UK |\n",
    "  Vidhya |6127|   64921  |    3158    | 101.99|  ***** Mumbai, India | ***** Mumbai, India |\n",
    "  Vidhya |6127|   64989  |    2561    | 21.35 |  ***** Mumbai, India | ***** Mumbai, India |\n",
    "  Vidhya |6127|   64989  |     89     | 16.95 |  ***** Mumbai, India | ***** Mumbai, India |\n",
    "  Stuart |5692|   65271  |    103     |  6.95 |  ***** Dover, UK | ***** Dover, UK |  \n",
    "\n",
    "In the above table we've reproduced many values several times such as customer names and IDs, addresses, prices, etc. We could break up this table into several smaller tables in which relations contain the minimal amount of attributes needed to define the relation. For instance, we may have a table for customers, a table for products, and a table for orders.\n",
    "\n",
    "  Customer | ID | Billing Address\n",
    " :--------:|:--:|:---------------:\n",
    "    Omar   | 435| ***** Berlin, Germany\n",
    "   Stuart  |5692| ***** Dover, UK\n",
    "   Vidhya  |6127| ***** Mumbai, India\n",
    "\n",
    " Product ID | Price\n",
    ":----------:|:-----:\n",
    "    103     |  6.95\n",
    "   4028     | 35.50\n",
    "   3158     | 101.99\n",
    "   2561     | 21.35\n",
    "    89      | 16.95\n",
    "\n",
    " Order ID | Customer ID | Product ID | Delivery Address\n",
    ":--------:|:-----------:|:----------:|:----------------:\n",
    "   62353  |     435     |    103     | ***** Munich, Germany\n",
    "   62353  |     435     |    4028    | ***** Tunis, Tunisia\n",
    "   64598  |    5692     |    103     | ***** Dover, UK\n",
    "   64921  |    6127     |    3158    | ***** Mumbai, India\n",
    "   64989  |    6127     |    2561    | ***** Mumbai, India\n",
    "   64989  |    6127     |     89     | ***** Mumbai, India\n",
    "   65271  |    5692     |    103     | ***** Dover, UK\n",
    "\n",
    "Before we were storing 7 rows x 7 columns = 49 cells; now we're storing only 7 x 4 + 5 x 2 + 3 x 3 = 47 cells. This may not seem like a huge improvement, but realistically an online retailer may have millions of orders of a particular product. Reproducing the price in every order rather than storing it once per product could be quite costly when scaled up.\n",
    "\n",
    "Let's explore how this would be implemented in SQL. We'll use `sqlite`, a basic SQL database manager that is useful for small data analysis and instructional purposes.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data in SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sql\n",
    "%sql sqlite:///testdb.sqlite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "--# The %%sql magic tells Jupyter to interpret this cell as SQL\n",
    "--# In SQL comments begin with \"--\" (we add # to take advantage of Jupyter's syntax highlighting)\n",
    "\n",
    "--# Since we're starting a new example, let's delete any existing tables\n",
    "DROP TABLE IF EXISTS customers;\n",
    "DROP TABLE IF EXISTS products;\n",
    "DROP TABLE IF EXISTS orders;\n",
    "\n",
    "--# Now let's make our tables\n",
    "CREATE TABLE customers (\n",
    "    id                 INTEGER PRIMARY KEY NOT NULL,\n",
    "    name               TEXT NOT NULL,\n",
    "    billing_address    TEXT NOT NULL\n",
    ");\n",
    "\n",
    "CREATE TABLE products (\n",
    "    id                 INTEGER PRIMARY KEY NOT NULL,\n",
    "    price              NUMBER NOT NULL\n",
    ");\n",
    "\n",
    "CREATE TABLE orders (\n",
    "    id                 INTEGER NOT NULL,\n",
    "    customer_id        NUMBER NOT NULL,\n",
    "    product_id         NUMBER NOT NULL,\n",
    "    delivery_address   TEXT NOT NULL,\n",
    "    FOREIGN KEY(customer_id) REFERENCES customers(id),\n",
    "    FOREIGN KEY(product_id) REFERENCES products(id)\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our tables are initially empty, but we have defined the **schema** or structure of the tables. We've specified certain options in our schema, such as the fact that we do not accept null values in any field and that certain fields are unique primary keys. Many more options are possible, including setting default values for fields that could otherwise be null or instructing SQL to automatically assign incrementing values. If you haven't gotten the sense already, database architecture is an extensive subject!\n",
    "\n",
    "We can inspect the table by using `SELECT`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT * FROM customers;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's `INSERT` data into our tables.\n",
    "\n",
    "We have to be careful to do this in a certain order; when we defined the `orders` table, we defined a relationship between the `customer_id` and `product_id` attributes and the `id` attributes in the `customer` and `product` tables respectively. We can only `INSERT`  data into the orders table once the appropriate customers and products exist in their tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "--# Starting with customers\n",
    "\n",
    "INSERT INTO customers (id, name, billing_address)\n",
    "    VALUES (435, 'Omar', 'Berlin, Germany'), (5692, 'Stuart', 'Dover, UK'), (6127, 'Vidhya', 'Mumbai, India');\n",
    "\n",
    "INSERT INTO products (id, price)\n",
    "    VALUES (103, 6.95), (4028, 35.5), (3158, 101.99), (2561, 21.35), (89, 16.95);\n",
    "\n",
    "INSERT INTO orders (id, customer_id, product_id, delivery_address)\n",
    "    VALUES (62353, 435, 103, 'Munich, Germany'), (62353, 435, 4028, 'Tunis, Tunisia');\n",
    "\n",
    "INSERT INTO orders (id, customer_id, product_id, delivery_address)\n",
    "    VALUES (64598, 5692, 103, 'Dover, UK'), (65271, 5692, 103, 'Dover, UK');\n",
    "\n",
    "INSERT INTO orders (id, customer_id, product_id, delivery_address)\n",
    "    VALUES (64921, 6127, 3158, 'Mumbai, India'), (64989, 6127, 2561, 'Mumbai, India'), (64989, 6127, 89, 'Mumbai, India');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's confirm that our tables have been updated with the data from our example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT * FROM customers;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT * FROM products;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT * FROM orders;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Databases are commonly used for persistent data storage, and therefore it is common to add or remove rows as new data is created (e.g. someone places an order) or destroyed (e.g. a product is discontinued). This may be performed automatically via an application's **database connection**; we will use database connections later in this notebook. However, in the mean time we will load in a larger version of the above data set from file for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect(\"testdb.sqlite\")\n",
    "customers = pd.read_csv('data/customers.csv')\n",
    "products = pd.read_csv('data/products.csv')\n",
    "orders = pd.read_csv('data/orders.csv')\n",
    "\n",
    "customers.to_sql(\"customers\", conn, index=False, if_exists=\"replace\")\n",
    "products.to_sql(\"products\", conn, index=False, if_exists=\"replace\")\n",
    "orders.to_sql(\"orders\", conn, index=False, if_exists=\"replace\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering and sorting data\n",
    "\n",
    "Filtering is principally accomplished using the `WHERE` command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT id, delivery_country FROM orders\n",
    "WHERE delivery_country = 'India'\n",
    "LIMIT 10;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT * FROM products\n",
    "WHERE price > 20\n",
    "LIMIT 10;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can additionally combine `WHERE` with `LIKE` for pattern matching an `IN` for membership."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT id, delivery_country FROM orders\n",
    "WHERE delivery_country like 'S%'\n",
    "LIMIT 10;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT * FROM orders\n",
    "WHERE customer_id IN (10, 200, 400);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also combine them with the usual logical operators: `AND`, `OR`, and `NOT`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT * FROM orders\n",
    "WHERE customer_id IN (10, 200, 400)\n",
    "AND delivery_country NOT IN ('Madagascar', 'Canada');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT * FROM products\n",
    "WHERE price < 10 OR price > 30\n",
    "LIMIT 10;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To sort our results, we can `ORDER BY` one or more columns. We can also choose whether we sort in ascending (`ASC`) or descending (`DESC`) order. SQL sorts in ascending order by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT * FROM orders\n",
    "ORDER BY customer_id\n",
    "LIMIT 10;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT * FROM orders\n",
    "ORDER BY customer_id ASC, product_id DESC\n",
    "LIMIT 10;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data aggregation\n",
    "\n",
    "Most of the standard data aggregation functions are available in SQL (`COUNT`, `SUM`, `DISTINCT`, `MAX`, etc.) although exactly what is available and what it is called varies by dialect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT AVG(price), MAX(price) FROM products;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, we are often interested in aggregating our data within certain groups. As in Pandas, we will use `GROUP BY` to accomplish this. Remember -- if we are performing a `groupby`, any other attributes we select must be aggregated by some aggregation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT delivery_country, COUNT(DISTINCT(id)) FROM orders\n",
    "GROUP BY delivery_country\n",
    "LIMIT 10;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joining tables together\n",
    "\n",
    "Since we have split up our data among several tables to reduce redundancy, we will have to join tables together to compute certain values we might be interested in. For instance, how might we calculate the total revenue from all orders? We could take a sum of the price associated with each item in each order, but in order to do so, we must `JOIN` the `products` table to the `orders` table `ON` the shared attribute: `product_id` (from the `orders` table) and `id` (from the `products` table).\n",
    "\n",
    "Since joins involve fields from multiple tables, we'll frequently alias a table `AS` some abbreviation to save ourselves some typing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT SUM(p.price) FROM orders AS o\n",
    "JOIN products AS p ON o.product_id = p.id;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are often several ways to perform a join. We can usually rely on our database management software to work out the details of the most efficient way to perform the join, although there are exceptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT SUM(p.price)\n",
    "FROM orders o, products p\n",
    "WHERE p.id = o.product_id;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT c.name, SUM(p.price) total\n",
    "FROM orders o, products p, customers c\n",
    "WHERE p.id = o.product_id AND c.id = o.customer_id\n",
    "GROUP BY c.id\n",
    "ORDER BY total\n",
    "LIMIT 10;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try something more complex. Let's find the total amount of money spent on orders that are shipped internationally for each `billing_country`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT shp.bill, SUM(shp.rev) spent\n",
    "FROM (SELECT c.billing_country bill, o.delivery_country deliver, SUM(p.price) rev\n",
    "      FROM orders o, customers c, products p\n",
    "      WHERE o.customer_id = c.id AND o.product_id = p.id\n",
    "      GROUP BY bill, deliver\n",
    "      HAVING bill != deliver) shp\n",
    "GROUP BY shp.bill\n",
    "ORDER BY spent DESC\n",
    "LIMIT 10;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above example makes use of a subquery. Subqueries are often used for constructing intermediate tables that we may use in the computation of a larger query, and are frequently used as part of joins or to perform joins."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connecting to a database from Python\n",
    "\n",
    "In order to load our example data into our database, we created a **database connection**. We then read in our data files with Pandas, and pushed them through the connection to the database. We could have read this data directly into SQL, but database connections allow us to pass data between Python and SQL, allowing web applications or machine learning models operating in Python easy access to persistent databases.\n",
    "\n",
    "In our case, we used the `sqlite3` module because we are creating a connection to SQLite. There are other connectors for other dialects such a `psycopg2` for PostgreSQL and `mysql` for MySQL. Other packages such as `SQLAlchemy` provide connectors as well as object-relation mapping (ORM), which we will discuss later.\n",
    "\n",
    "Database connections will typically resemble the example set above\n",
    "\n",
    "```python\n",
    "conn = sqlite3.connect(\"testdb.sqlite\")\n",
    "```\n",
    "\n",
    "possibly using a URL for connecting to a remotely hosted database and extra parameters for authentication. We can combine the connection with Pandas methods for [reading from](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_sql.html) and [writing to](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.to_sql.html) SQL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Copyright &copy; 2020 The Data Incubator.  All rights reserved.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "nbclean": true
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
