{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "%logstop\n",
    "%logstart -rtq ~/.logs/PY_Algorithms.py append\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "matplotlib.rcParams['figure.dpi'] = 144"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import expectexception"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have learned a bit about how to program in Python and some ways in which we can make our code more Pythonic.  However, programming is not only about making the computer do work for us, its about optimizing the amount of work the computer needs to do.  There are multiple types of work we can consider, but here we will consider three major bottlenecks in code:\n",
    "\n",
    "1. _Computational Complexity_ - how many instructions are executed?\n",
    "2. _Memory Needs_ - how much memory is needed?\n",
    "3. _I/O_ - How many reads and writes or network requests do I need to make?\n",
    "\n",
    "An *Algorithm* is a procedure for solving a problem.  It describes a sequence of operations then when performed will result in a solution to a problem.  There are many types of algorithms, some are guaranteed find a solution, some do not. Often we are interested in understanding the performance of an algorithm in terms of the three bottlenecks listed above (as well as others).  In order to analyze these algorithms, we need to develop some tools to understand how algorithms behave as a function of the problem size.\n",
    "\n",
    "## Big O\n",
    "\n",
    "In order to quantify the complexity of a particular algorithm, we can consider how the algorithm grows with respect to the size of the problem.  For the purposes of this notebook we will only consider problems that are one dimensional, so we can quantify the algorithm with respect to a single number, which we will denote as $N$.  Remember that a problem itself does not have a complexity, rather it is the algorithmic solution which has complexity.  For example, lets consider the problem of summing all the numbers between 1 and $N$ (inclusive).  On way to sum this might be to take the of all of these numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_num(N):\n",
    "    sum_ = 0\n",
    "    for n in range(N + 1):\n",
    "        sum_ += n\n",
    "    return sum_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This algorithm will be $O(N)$ because we need to perform about $N$ operations.  Note that we only care about the dominant function of $N$ in the expansion so for our purposes $O(N) \\approx O(N+1) \\approx O(2N)$.\n",
    "\n",
    "However, if we remember think a bit about how numbers sum, we can invoke a summation rule often attributed to Gauss which says that \n",
    "$$\\sum_{n=1}^{N} n = \\frac{N(N+1)}{2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_gauss(N):\n",
    "    return N*(N+1)//2 # We can use integer division here, why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This algorithm is $O(1)$ because it does not depend on how the size of $N$!.  Lets just check that it gives the same answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for N in range(100):\n",
    "    assert sum_num(N) == sum_gauss(N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets plot the time it takes to compute these functions as a function of $N$.  We will use a package called `matplotlib` to do some plotting, don't worry, we will learn about it later!\n",
    "\n",
    "We will time how long it takes to perform both of these algorithms.  We will take the mean of several runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "def compute(n_avgs, func, N):\n",
    "    times = []\n",
    "    for _ in range(n_avgs):\n",
    "        ts = time.time()\n",
    "        func(N)\n",
    "        times.append(time.time() - ts)\n",
    "    return sum(times)/float(len(times)) * 1000 # milliseconds\n",
    "\n",
    "n_avgs = 100\n",
    "time_sum = []\n",
    "time_gauss = []\n",
    "N_range = range(10,100000, 5000)\n",
    "for N in N_range:\n",
    "    time_sum.append(compute(n_avgs, sum_num, N))\n",
    "    time_gauss.append(compute(n_avgs, sum_gauss, N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(N_range, time_sum, 'o-', label='Sum Numbers')\n",
    "plt.plot(N_range, time_gauss, 'o-', label='Gauss')\n",
    "plt.xlabel('N')\n",
    "plt.ylabel('Average time (ms)')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computational Complexity\n",
    "\n",
    "Lets solve a version of a common problem you might find as a data scientist, how should I store my data?  Lets take a very simple case where our data is just a list of numbers and we need to store this in a list?  In there any way to optimize the storage?\n",
    "\n",
    "Lets consider the tradeoffs for various things we might want to do in the list.  \n",
    "\n",
    "### Finding an element\n",
    "\n",
    "If we want to find an element in a list and we know nothing about that list, then we need to check every element in the list to see if that element is there.  Lets write a function to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_ele(list_, ele):\n",
    "    for i in list_:\n",
    "        if i == ele:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to test these, lets use the `random` module to generate a list of random numbers between $0$ and $10 *N$ where $N$ is the length of the list we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def random_list(N, sort=False):\n",
    "    list_ = [random.randint(0, 10*N) for _ in range(N)]\n",
    "    return sorted(list_) if sort else list_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_list(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def time_func(func, *args):\n",
    "    ts = time.time()\n",
    "    func(*args)\n",
    "    return time.time() - ts\n",
    "\n",
    "def compute_with_list(n_avgs, N, sort, *funcs):\n",
    "    ans = []\n",
    "    for _ in range(n_avgs):\n",
    "        list_r = random_list(N, sort)\n",
    "        n_to_find = random.randint(0, 10*N)\n",
    "        ans.append([time_func(func, list_r, n_to_find)\n",
    "                for func in funcs])\n",
    "    # now find avg\n",
    "    return np.array(ans).mean(axis=0)*1000\n",
    "    \n",
    "\n",
    "n_avgs = 40\n",
    "N_range = range(10, 100000, 10000)\n",
    "time_list = np.array([compute_with_list(n_avgs, N, False, find_ele) for N in N_range])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(N_range, time_list, 'o-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us take a slightly different approach where we know that this list sorted.  Note that sorting itself is $N\\log(N)$ complexity, so although we will be able to perform optimized searches on a sorted list, its not in general faster to sort and then find the elements.  However, if we know we will be searching often, we can build up the list as a sorted structure and for now we can assume that we have already done so.\n",
    "\n",
    "The most basic optimization we can perform is to only check until we have seen a number greater than what we are looking for.  Since we know the list is sorted, we are guaranteed to not find the number in the rest of the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_ele_sorted(list_, ele):\n",
    "    for i in list_:\n",
    "        if i == ele:\n",
    "            return True\n",
    "        if i > ele:\n",
    "            return False\n",
    "    return False\n",
    "\n",
    "n_avgs = 40\n",
    "N_range = range(10, 100000, 10000)\n",
    "time_list = np.array([compute_with_list(n_avgs, N, True, find_ele, find_ele_sorted) for N in N_range])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(N_range, time_list[:,0], 'o-', label='find_ele')\n",
    "plt.plot(N_range, time_list[:,1], 'o-', label='find_ele_sorted')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This does better on average, but it still has the same $O(N)$ runtime.  Such optimizations are useful, but we can do better.  Lets implement what is sometimes known as binary search.  This is a recursive algorithm that allows the list to be divided roughly in half on each recursive step.  this will yield logarithmic asymptotic run time.  Lets first illustrate the algorithm by walking through an example where `l_=[1,2,3,4,5,6,7,8,9,10,11]` and we want to check if 2 is contained in the list.\n",
    "\n",
    "First we check the midpoint of the list, which is 6.  We know that 2 does not equal 6, but since the list is sorted, we can immediately rule out the part of the list containing numbers greater than 6.  Thus we have already ruled out half the elements of the list. \n",
    "\n",
    "Now we can ask the question is 2 contained in list `[1,2,3,4,5]`.  First we check the midpoint element of the list, which is 3.  We know that 3 is not 2, but again, since $3>2$, we can eliminate half the list.\n",
    "\n",
    "Now we can check if 2 is contained in the list `[1,2]`.  We will take midpoint of this list as the first element (since it has index $1=len(list)/2$), and this is equal to 2.  Thus 2 is in the original list.\n",
    "\n",
    "We can see we have performed this search in only three steps and up to an extra step, this did not depend on where 2 was in the list, only that it was sorted.  Since we are removing half the list each time, we expect that the number of steps will be roughly $log(N)$, where the logarithm is understood to be base 2.  Lets make a plot of this function compared to $N$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(10, 2000, 200)\n",
    "plt.plot(x, np.log(x)/x)\n",
    "plt.xlabel('N')\n",
    "plt.ylabel(r'$\\log(x)/x$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can compare this to our other search algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_ele_binary(l_, ele):\n",
    "    if len(l_) < 1:\n",
    "        return False\n",
    "    mid_point = len(l_)//2\n",
    "    if l_[mid_point] == ele:\n",
    "        return True\n",
    "    elif l_[mid_point] > ele:\n",
    "        return find_ele_binary(l_[:mid_point], ele)\n",
    "    else:\n",
    "        return find_ele_binary(l_[mid_point+1:], ele)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_avgs = 50\n",
    "N_range = np.arange(1000, 70000, 8000)\n",
    "time_list = np.array([compute_with_list(n_avgs, N, True, find_ele_sorted, find_ele_binary) for N in N_range])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, func in enumerate(['find_ele_sorted', 'find_ele_binary']):\n",
    "    l, = plt.plot(N_range, 2**time_list[:, i], 'o-', label=func)\n",
    "    # fit a line to the exponent\n",
    "    p = np.polyfit(N_range, 2**time_list[:, i], 1)\n",
    "    plt.plot(N_range, N_range * p[0] + p[1], color=l.get_color())\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, if we are only keeping track of what numbers we have seen, we can use something like a `set` which will be $O(1)$ access."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memoization\n",
    "\n",
    "Often we can get a performance increase just by not recomputing things we have already computed!  Let's look again at our recursive Fibonacci sequence defined in a previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fibonacci_recursive(n):\n",
    "    if n == 0:\n",
    "        return 0\n",
    "    elif n == 1:\n",
    "        return 1\n",
    "    else:\n",
    "        return fibonacci_recursive(n-1)  + fibonacci_recursive(n-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets make a slightly different version which keeps track of how many times we call the function on each element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "def fibonacci_count(n, d):\n",
    "    d[n] += 1\n",
    "    if n == 0:\n",
    "        return 0, d\n",
    "    elif n == 1:\n",
    "        return 1, d\n",
    "    else:\n",
    "        n1, _ = fibonacci_count(n-1, d)\n",
    "        n2, _ = fibonacci_count(n-2, d)\n",
    "        return n1 + n2, d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see this in action for $N=5$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 5\n",
    "ans, d = fibonacci_count(N, defaultdict(int))\n",
    "for i in range(N):\n",
    "    print(i, d[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "              5\n",
    "          4       3\n",
    "         3 2     2 1\n",
    "       2 1 1 0  1 0\n",
    "      1 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets look for $N=25$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 25\n",
    "ans, d = fibonacci_count(N, defaultdict(int))\n",
    "print(ans)\n",
    "for i in range(N):\n",
    "    print(i, d[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we are calling some of these functions with the same argument thousands of time.  If we store the answer to the problem instead of recomputing it, can we do any better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fibonacci_mem(n, d):\n",
    "    if n in d:\n",
    "        return d[n]\n",
    "    elif n == 0:\n",
    "        ans = 0\n",
    "    elif n == 1:\n",
    "        ans = 1\n",
    "    else:\n",
    "        ans = fibonacci_mem(n-1, d) + fibonacci_mem(n-2, d)\n",
    "    d[n] = ans\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "fibonacci_mem(33, {0:0,1:1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "fibonacci_recursive(33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fibonacci_mem(33, {}) == fibonacci_recursive(33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our memoized solution does much better, it is several orders of magnitude faster than the bare recursive solution.  \n",
    "\n",
    "However, it does come at a cost, although we save computation, we must use more memory to store the previous result.  Often there will be a tradeoff between the two."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "1. Write the factorial function $f(n) = n!$ as a recursive function.\n",
    "2. Would memoization make this function faster?\n",
    "3. Now what if we needed to calculate the factorial often (perhaps we were computing probabilities of different selections), would memoization be useful in this case?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory\n",
    "As seen before memoization has a tradeoff in terms of memory.  Lets try to describe that here for the case of the Fibonacci sequence.  We have to keep track of a single element number (the computed solution) for all number less than $N$, the number we want to compute.  Thus the memory we need grows with problem size as $O(N)$.\n",
    "\n",
    "We can analyze our algorithms in terms of memory in a similar way.  Again remember, it is the algorithm (and its implementation) which has memory complexity, not the problem itself.  \n",
    "\n",
    "For our first problem, we will again look at summing the numbers between 0 and $N$, and we will take two different approaches.\n",
    "\n",
    "For the first we will build a list of these elements and then sum them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_list(n):\n",
    "    numbers = range(n)\n",
    "    return sum(numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_iter(n):\n",
    "    number = 0\n",
    "    sum_ = 0\n",
    "    while number < n:\n",
    "        sum_ += number\n",
    "        number += 1\n",
    "    return sum_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_list(100), sum_iter(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose a data structure wisely\n",
    "\n",
    "As we may have noticed in the sorting section, the type of data structure we use is often tied into our choice of algorithm.  For example, if we don't already have sorted data, we probably don't want to use binary search because we would need to sort the data first and then would negate any search improvement (sorting is worse than $O(N)$).  \n",
    "\n",
    "This can be mitigated by choosing our original structure wisely, especially when get to build it from raw data.  For example when building a list, inserting elements in a sorted manner can be done in $O(log(N))$ time (with almost the same as binary search).  \n",
    "\n",
    "Other data structures lend themselves to other algorithmic purposes..  For example, a `heap` (implemented in Python with the [`heapq`](https://docs.python.org/2/library/heapq.html) library) implements a tree like structure which is useful for order statistics, such as keeping track of the largest or smallest $N$ items in a collection.  You can read more about it [here](https://en.wikipedia.org/wiki/Binary_heap).\n",
    "\n",
    "Even as you work through your miniprojects, sometimes choosing a dictionary instead of a list will be the difference between minutes or seconds of computation.\n",
    "\n",
    "### Exercises\n",
    "\n",
    "1. Explain why sorting and then using binary search is slower than just searching.\n",
    "2. Implement insertion on a list using the same principles as binary search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Copyright &copy; 2020 The Data Incubator.  All rights reserved.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "nbclean": true
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
