{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## SVM regression models\n",
    "## K-Nearest Neighbor regression models\n",
    "## Decision Tree regression models\n",
    "## Ensemble regression models\n",
    "### Patrick ğŸŒ°"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _boston_dataset:\n",
      "\n",
      "Boston house prices dataset\n",
      "---------------------------\n",
      "\n",
      "**Data Set Characteristics:**  \n",
      "\n",
      "    :Number of Instances: 506 \n",
      "\n",
      "    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\n",
      "\n",
      "    :Attribute Information (in order):\n",
      "        - CRIM     per capita crime rate by town\n",
      "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
      "        - INDUS    proportion of non-retail business acres per town\n",
      "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
      "        - NOX      nitric oxides concentration (parts per 10 million)\n",
      "        - RM       average number of rooms per dwelling\n",
      "        - AGE      proportion of owner-occupied units built prior to 1940\n",
      "        - DIS      weighted distances to five Boston employment centres\n",
      "        - RAD      index of accessibility to radial highways\n",
      "        - TAX      full-value property-tax rate per $10,000\n",
      "        - PTRATIO  pupil-teacher ratio by town\n",
      "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
      "        - LSTAT    % lower status of the population\n",
      "        - MEDV     Median value of owner-occupied homes in $1000's\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
      "\n",
      "This is a copy of UCI ML housing dataset.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/housing/\n",
      "\n",
      "\n",
      "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
      "\n",
      "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
      "prices and the demand for clean air', J. Environ. Economics & Management,\n",
      "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
      "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
      "pages 244-261 of the latter.\n",
      "\n",
      "The Boston house-price data has been used in many machine learning papers that address regression\n",
      "problems.   \n",
      "     \n",
      ".. topic:: References\n",
      "\n",
      "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
      "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ä»sklearn.datasetså¯¼å…¥æ³¢å£«é¡¿æˆ¿ä»·æ•°æ®è¯»å–å™¨ã€‚\n",
    "from sklearn.datasets import load_boston\n",
    "# ä»è¯»å–æˆ¿ä»·æ•°æ®å­˜å‚¨åœ¨å˜é‡bostonä¸­ã€‚\n",
    "boston = load_boston()\n",
    "# è¾“å‡ºæ•°æ®æè¿°ã€‚\n",
    "print (boston.DESCR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The max target value is 50.0\n",
      "The min target value is 5.0\n",
      "The average target value is 22.532806324110677\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "X = boston.data\n",
    "y = boston.target\n",
    "\n",
    "# éšæœºé‡‡æ ·25%çš„æ•°æ®æ„å»ºæµ‹è¯•æ ·æœ¬ï¼Œå…¶ä½™ä½œä¸ºè®­ç»ƒæ ·æœ¬ã€‚\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=33, test_size=0.25)\n",
    "\n",
    "# åˆ†æå›å½’ç›®æ ‡å€¼çš„å·®å¼‚ã€‚\n",
    "print (\"The max target value is\", np.max(boston.target))\n",
    "print (\"The min target value is\", np.min(boston.target))\n",
    "print (\"The average target value is\", np.mean(boston.target))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## è®­ç»ƒä¸æµ‹è¯•æ•°æ®æ ‡å‡†åŒ–å¤„ç†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä»sklearn.preprocessingå¯¼å…¥æ•°æ®æ ‡å‡†åŒ–æ¨¡å—ã€‚\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# åˆ†åˆ«åˆå§‹åŒ–å¯¹ç‰¹å¾å’Œç›®æ ‡å€¼çš„æ ‡å‡†åŒ–å™¨ã€‚\n",
    "ss_X = StandardScaler()\n",
    "ss_y = StandardScaler()\n",
    "# must reshape the y_test and y_train\n",
    "y_test= y_test.reshape(-1,1)\n",
    "y_train = y_train.reshape(-1,1)\n",
    "# åˆ†åˆ«å¯¹è®­ç»ƒå’Œæµ‹è¯•æ•°æ®çš„ç‰¹å¾ä»¥åŠç›®æ ‡å€¼è¿›è¡Œæ ‡å‡†åŒ–å¤„ç†ã€‚\n",
    "X_train = ss_X.fit_transform(X_train)\n",
    "X_test = ss_X.transform(X_test)\n",
    "\n",
    "y_train = ss_y.fit_transform(y_train)\n",
    "y_test = ss_y.transform(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:No traceback has been produced, nothing to debug.\n"
     ]
    }
   ],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## çº¿æ€§å›å½’æ¨¡å‹ Linear regression & SGDRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä»sklearn.linear_modelå¯¼å…¥LinearRegressionã€‚\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# ä½¿ç”¨é»˜è®¤é…ç½®åˆå§‹åŒ–çº¿æ€§å›å½’å™¨LinearRegressionã€‚\n",
    "lr = LinearRegression()\n",
    "# ä½¿ç”¨è®­ç»ƒæ•°æ®è¿›è¡Œå‚æ•°ä¼°è®¡ã€‚\n",
    "lr.fit(X_train, y_train)\n",
    "# å¯¹æµ‹è¯•æ•°æ®è¿›è¡Œå›å½’é¢„æµ‹ã€‚\n",
    "lr_y_predict = lr.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lipengyuan/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/Users/lipengyuan/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# ä»sklearn.linear_modelå¯¼å…¥SGDRegressorã€‚\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "# ä½¿ç”¨é»˜è®¤é…ç½®åˆå§‹åŒ–çº¿æ€§å›å½’å™¨SGDRegressorã€‚\n",
    "sgdr = SGDRegressor()\n",
    "# ä½¿ç”¨è®­ç»ƒæ•°æ®è¿›è¡Œå‚æ•°ä¼°è®¡ã€‚\n",
    "sgdr.fit(X_train, y_train)\n",
    "# å¯¹æµ‹è¯•æ•°æ®è¿›è¡Œå›å½’é¢„æµ‹ã€‚\n",
    "sgdr_y_predict = sgdr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The value of default measurement of LinearRegression is 0.675795501452948\n",
      "The value of R-squared of LinearRegression is 0.675795501452948\n",
      "The mean squared error of LinearRegression is 25.139236520353457\n",
      "The mean absoluate error of LinearRegression is 3.5325325437053983\n"
     ]
    }
   ],
   "source": [
    "# ä½¿ç”¨LinearRegressionæ¨¡å‹è‡ªå¸¦çš„è¯„ä¼°æ¨¡å—ï¼Œå¹¶è¾“å‡ºè¯„ä¼°ç»“æœã€‚\n",
    "print ('The value of default measurement of LinearRegression is', lr.score(X_test, y_test))\n",
    "\n",
    "# ä»sklearn.metricsä¾æ¬¡å¯¼å…¥r2_scoreã€mean_squared_errorä»¥åŠmean_absoluate_errorç”¨äºå›å½’æ€§èƒ½çš„è¯„ä¼°ã€‚\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "# ä½¿ç”¨r2_scoreæ¨¡å—ï¼Œå¹¶è¾“å‡ºè¯„ä¼°ç»“æœã€‚\n",
    "print ('The value of R-squared of LinearRegression is', r2_score(y_test, lr_y_predict))\n",
    "\n",
    "# ä½¿ç”¨mean_squared_erroræ¨¡å—ï¼Œå¹¶è¾“å‡ºè¯„ä¼°ç»“æœã€‚\n",
    "print ('The mean squared error of LinearRegression is', mean_squared_error(ss_y.inverse_transform(y_test), ss_y.inverse_transform(lr_y_predict)))\n",
    "\n",
    "# ä½¿ç”¨mean_absolute_erroræ¨¡å—ï¼Œå¹¶è¾“å‡ºè¯„ä¼°ç»“æœã€‚\n",
    "print ('The mean absoluate error of LinearRegression is', mean_absolute_error(ss_y.inverse_transform(y_test), ss_y.inverse_transform(lr_y_predict)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The value of default measurement of SGDRegressor is 0.6585897732863233\n",
      "The value of R-squared of SGDRegressor is 0.6585897732863233\n",
      "The mean squared error of SGDRegressor is 26.473390956285545\n",
      "The mean absoluate error of SGDRegressor is 3.549437134404973\n"
     ]
    }
   ],
   "source": [
    "# ä½¿ç”¨SGDRegressoræ¨¡å‹è‡ªå¸¦çš„è¯„ä¼°æ¨¡å—ï¼Œå¹¶è¾“å‡ºè¯„ä¼°ç»“æœã€‚\n",
    "print ('The value of default measurement of SGDRegressor is', sgdr.score(X_test, y_test))\n",
    "\n",
    "# ä½¿ç”¨r2_scoreæ¨¡å—ï¼Œå¹¶è¾“å‡ºè¯„ä¼°ç»“æœã€‚\n",
    "print ('The value of R-squared of SGDRegressor is', r2_score(y_test, sgdr_y_predict))\n",
    "\n",
    "# ä½¿ç”¨mean_squared_erroræ¨¡å—ï¼Œå¹¶è¾“å‡ºè¯„ä¼°ç»“æœã€‚\n",
    "print( 'The mean squared error of SGDRegressor is', mean_squared_error(ss_y.inverse_transform(y_test), ss_y.inverse_transform(sgdr_y_predict)))\n",
    "\n",
    "# ä½¿ç”¨mean_absolute_erroræ¨¡å—ï¼Œå¹¶è¾“å‡ºè¯„ä¼°ç»“æœã€‚\n",
    "print ('The mean absoluate error of SGDRegressor is', mean_absolute_error(ss_y.inverse_transform(y_test), ss_y.inverse_transform(sgdr_y_predict)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* çº¿æ€§å›å½’å™¨æ˜¯æœ€ä¸ºç®€å•ã€æ˜“ç”¨çš„å›å½’æ¨¡å‹ã€‚æ­£æ˜¯å› ä¸ºå…¶å¯¹ç‰¹å¾ä¸å›å½’ç›®æ ‡ä¹‹é—´çš„çº¿æ€§å‡è®¾ï¼Œä»æŸç§ç¨‹åº¦ä¸Šè¯´ä¹Ÿæ˜¯å±€é™äº†å…¶åº”ç”¨èŒƒå›´ã€‚ç‰¹åˆ«æ˜¯ï¼Œç°å®ç”Ÿæ´»ä¸­çš„è®¸å¤šå®ä¾‹æ•°æ®çš„å„ä¸ªç‰¹å¾ä¸å›å½’ç›®æ ‡ä¹‹é—´ï¼Œç»å¤§å¤šæ•°ä¸èƒ½ä¿è¯ä¸¥æ ¼çš„çº¿æ€§å…³ç³»ã€‚å°½ç®¡å¦‚æ­¤ï¼Œåœ¨ä¸æ¸…æ¥šç‰¹å¾ä¹‹é—´å…³ç³»çš„å‰æä¸‹ï¼Œæˆ‘ä»¬ä»ç„¶å¯ä»¥ä½¿ç”¨çº¿æ€§å›å½’æ¨¡å‹ä½œä¸ºå¤§å¤šæ•°ç§‘å­¦å®éªŒçš„åŸºçº¿ç³»ç»Ÿã€‚\n",
    "* Linear Regressor is the simplest and easiest regression model. It is precisely because of its linear assumption between the feature and the regression goal that it limits the scope of its application to some extent. In particular, the vast majority of the characteristics of many instances of real-life data and regression goals do not guarantee a strictly linear relationship. Nevertheless, we can still use linear regression models as the baseline system for most scientific experiments without knowing the relationship between features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æ”¯æŒå‘é‡æœºå›å½’\n",
    "* ä½¿ç”¨ä¸‰ç§ä¸åŒæ ¸å‡½æ•°é…ç½®çš„æ”¯æŒå‘é‡æœºå›å½’æ¨¡å‹è¿›è¡Œè®­ç»ƒï¼Œå¹¶ä¸”åˆ†åˆ«å¯¹æµ‹è¯•æ•°æ®ä½œå‡ºé¢„æµ‹\n",
    "* å¯¹ä¸‰ç§æ ¸å‡½æ•°é…ç½®ä¸‹çš„æ”¯æŒå‘é‡æœºå›å½’æ¨¡å‹åœ¨ç›¸åŒæµ‹è¯•é›†ä¸Šè¿›è¡Œæ€§èƒ½è¯„ä¼°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lipengyuan/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/lipengyuan/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/lipengyuan/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# ä»sklearn.svmä¸­å¯¼å…¥æ”¯æŒå‘é‡æœºï¼ˆå›å½’ï¼‰æ¨¡å‹ã€‚\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# ä½¿ç”¨çº¿æ€§æ ¸å‡½æ•°é…ç½®çš„æ”¯æŒå‘é‡æœºè¿›è¡Œå›å½’è®­ç»ƒï¼Œå¹¶ä¸”å¯¹æµ‹è¯•æ ·æœ¬è¿›è¡Œé¢„æµ‹ã€‚\n",
    "linear_svr = SVR(kernel='linear')\n",
    "linear_svr.fit(X_train, y_train)\n",
    "linear_svr_y_predict = linear_svr.predict(X_test)\n",
    "\n",
    "# ä½¿ç”¨å¤šé¡¹å¼æ ¸å‡½æ•°é…ç½®çš„æ”¯æŒå‘é‡æœºè¿›è¡Œå›å½’è®­ç»ƒï¼Œå¹¶ä¸”å¯¹æµ‹è¯•æ ·æœ¬è¿›è¡Œé¢„æµ‹ã€‚\n",
    "poly_svr = SVR(kernel='poly')\n",
    "poly_svr.fit(X_train, y_train)\n",
    "poly_svr_y_predict = poly_svr.predict(X_test)\n",
    "\n",
    "# ä½¿ç”¨å¾„å‘åŸºæ ¸å‡½æ•°é…ç½®çš„æ”¯æŒå‘é‡æœºè¿›è¡Œå›å½’è®­ç»ƒï¼Œå¹¶ä¸”å¯¹æµ‹è¯•æ ·æœ¬è¿›è¡Œé¢„æµ‹ã€‚\n",
    "rbf_svr = SVR(kernel='rbf')\n",
    "rbf_svr.fit(X_train, y_train)\n",
    "rbf_svr_y_predict = rbf_svr.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared value of linear SVR is 0.650659546421538\n",
      "The mean squared error of linear SVR is 27.088311013556027\n",
      "The mean absoluate error of linear SVR is 3.4328013877599624\n"
     ]
    }
   ],
   "source": [
    "# ä½¿ç”¨R-squaredã€MSEå’ŒMAEæŒ‡æ ‡å¯¹ä¸‰ç§é…ç½®çš„æ”¯æŒå‘é‡æœºï¼ˆå›å½’ï¼‰æ¨¡å‹åœ¨ç›¸åŒæµ‹è¯•é›†ä¸Šè¿›è¡Œæ€§èƒ½è¯„ä¼°ã€‚\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "print ('R-squared value of linear SVR is', linear_svr.score(X_test, y_test))\n",
    "print ('The mean squared error of linear SVR is', mean_squared_error(ss_y.inverse_transform(y_test), ss_y.inverse_transform(linear_svr_y_predict)))\n",
    "print ('The mean absoluate error of linear SVR is', mean_absolute_error(ss_y.inverse_transform(y_test), ss_y.inverse_transform(linear_svr_y_predict)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared value of Poly SVR is 0.40365065102550846\n",
      "The mean squared error of Poly SVR is 46.24170053103929\n",
      "The mean absoluate error of Poly SVR is 3.73840737104651\n"
     ]
    }
   ],
   "source": [
    "print( 'R-squared value of Poly SVR is', poly_svr.score(X_test, y_test))\n",
    "print ('The mean squared error of Poly SVR is', mean_squared_error(ss_y.inverse_transform(y_test), ss_y.inverse_transform(poly_svr_y_predict)))\n",
    "print ('The mean absoluate error of Poly SVR is', mean_absolute_error(ss_y.inverse_transform(y_test), ss_y.inverse_transform(poly_svr_y_predict)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared value of RBF SVR is 0.7559887416340944\n",
      "The mean squared error of RBF SVR is 18.920948861538733\n",
      "The mean absoluate error of RBF SVR is 2.6067819999501114\n"
     ]
    }
   ],
   "source": [
    "print ('R-squared value of RBF SVR is', rbf_svr.score(X_test, y_test))\n",
    "print ('The mean squared error of RBF SVR is', mean_squared_error(ss_y.inverse_transform(y_test), ss_y.inverse_transform(rbf_svr_y_predict)))\n",
    "print ('The mean absoluate error of RBF SVR is', mean_absolute_error(ss_y.inverse_transform(y_test), ss_y.inverse_transform(rbf_svr_y_predict)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* å±•ç¤ºäº†ä¸åŒé…ç½®æ¨¡å‹åœ¨ç›¸åŒæ•°æ®ä¸Šæ‰€è¡¨ç°çš„æ€§èƒ½å·®å¼‚ï¼Œè¯¥ç³»åˆ—æ¨¡å‹è¿˜å¯ä»¥é€šè¿‡é…ç½®ä¸åŒçš„æ ¸å‡½æ•°æ¥æ”¹å˜æ¨¡å‹æ€§èƒ½ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K ä¸´è¿‘å›å½’\n",
    "* ä½¿ç”¨ä¸åŒé…ç½®çš„K ä¸´è¿‘å›å½’æ¨¡å‹å¯¹ç¾å›½æ³¢å£«é¡¿æˆ¿ä»·æ•°æ®è¿›è¡Œå›å½’é¢„æµ‹\n",
    "* å¯¹ä¸¤ç§ä¸åŒé…ç½®çš„K ä¸´è¿‘å›å½’æ¨¡å‹åœ¨ç¾å›½æ³¢å£«é¡¿æˆ¿ä»·æ•°æ®ä¸Šè¿›è¡Œé¢„æµ‹æ€§èƒ½çš„è¯„ä¼°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä»sklearn.neighborså¯¼å…¥KNeighborRegressorï¼ˆKè¿‘é‚»å›å½’å™¨ï¼‰ã€‚\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# åˆå§‹åŒ–Kè¿‘é‚»å›å½’å™¨ï¼Œå¹¶ä¸”è°ƒæ•´é…ç½®ï¼Œä½¿å¾—é¢„æµ‹çš„æ–¹å¼ä¸ºå¹³å‡å›å½’ï¼šweights='uniform'ã€‚\n",
    "uni_knr = KNeighborsRegressor(weights='uniform')\n",
    "uni_knr.fit(X_train, y_train)\n",
    "uni_knr_y_predict = uni_knr.predict(X_test)\n",
    "\n",
    "# åˆå§‹åŒ–Kè¿‘é‚»å›å½’å™¨ï¼Œå¹¶ä¸”è°ƒæ•´é…ç½®ï¼Œä½¿å¾—é¢„æµ‹çš„æ–¹å¼ä¸ºæ ¹æ®è·ç¦»åŠ æƒå›å½’ï¼šweights='distance'ã€‚\n",
    "dis_knr = KNeighborsRegressor(weights='distance')\n",
    "dis_knr.fit(X_train, y_train)\n",
    "dis_knr_y_predict = dis_knr.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared value of uniform-weighted KNeighorRegression: 0.6907212176346006\n",
      "The mean squared error of uniform-weighted KNeighorRegression: 23.981877165354337\n",
      "The mean absoluate error of uniform-weighted KNeighorRegression 2.9650393700787396\n"
     ]
    }
   ],
   "source": [
    "# ä½¿ç”¨R-squaredã€MSEä»¥åŠMAEä¸‰ç§æŒ‡æ ‡å¯¹å¹³å‡å›å½’é…ç½®çš„Kè¿‘é‚»æ¨¡å‹åœ¨æµ‹è¯•é›†ä¸Šè¿›è¡Œæ€§èƒ½è¯„ä¼°ã€‚\n",
    "print ('R-squared value of uniform-weighted KNeighorRegression:', uni_knr.score(X_test, y_test))\n",
    "print ('The mean squared error of uniform-weighted KNeighorRegression:', mean_squared_error(ss_y.inverse_transform(y_test), ss_y.inverse_transform(uni_knr_y_predict)))\n",
    "print ('The mean absoluate error of uniform-weighted KNeighorRegression', mean_absolute_error(ss_y.inverse_transform(y_test), ss_y.inverse_transform(uni_knr_y_predict)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared value of distance-weighted KNeighorRegression: 0.7201094821421603\n",
      "The mean squared error of distance-weighted KNeighorRegression: 21.703073090490353\n",
      "The mean absoluate error of distance-weighted KNeighorRegression: 2.801125502210876\n"
     ]
    }
   ],
   "source": [
    "# ä½¿ç”¨R-squaredã€MSEä»¥åŠMAEä¸‰ç§æŒ‡æ ‡å¯¹æ ¹æ®è·ç¦»åŠ æƒå›å½’é…ç½®çš„Kè¿‘é‚»æ¨¡å‹åœ¨æµ‹è¯•é›†ä¸Šè¿›è¡Œæ€§èƒ½è¯„ä¼°ã€‚\n",
    "print ('R-squared value of distance-weighted KNeighorRegression:', dis_knr.score(X_test, y_test))\n",
    "print ('The mean squared error of distance-weighted KNeighorRegression:', mean_squared_error(ss_y.inverse_transform(y_test), ss_y.inverse_transform(dis_knr_y_predict)))\n",
    "print ('The mean absoluate error of distance-weighted KNeighorRegression:', mean_absolute_error(ss_y.inverse_transform(y_test), ss_y.inverse_transform(dis_knr_y_predict))\t)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## å›å½’æ ‘\n",
    "* ä»é¢„æµ‹å€¼è¿ç»­è¿™ä¸ªæ„ä¹‰ä¸Šä¸¥æ ¼åœ°è®²ï¼Œå›å½’æ ‘ä¸èƒ½ç§°ä¸ºâ€œå›å½’ç®—æ³•â€ã€‚å› ä¸ºå›å½’æ ‘çš„å¶èŠ‚ç‚¹è¿”å›çš„æ˜¯â€œä¸€å›¢â€œ è®­ç»ƒæ•°æ®çš„å¹³å‡å€¼ï¼Œè€Œä¸æ˜¯å…·ä½“çš„ã€è¿ç»­çš„é¢„æµ‹å€¼ã€‚\n",
    "* ä½¿ç”¨å›å½’æ ‘å¯¹æ³¢å£«é¡¿æˆ¿ä»·è®­ç»ƒæ•°æ®è¿›è¡Œå­¦ä¹ ï¼Œå¹¶å¯¹æµ‹è¯•æ•°æ®è¿›è¡Œé¢„æµ‹\n",
    "* å¯¹å•ä¸€å›å½’æ ‘æ¨¡å‹åœ¨ç¾å›½æ³¢å£«é¡¿æˆ¿ä»·é¢„æµ‹æ•°æ®ä¸Šçš„é¢„æµ‹æ€§èƒ½è¿›è¡Œè¯„ä¼°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä»sklearn.treeä¸­å¯¼å…¥DecisionTreeRegressorã€‚\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "# ä½¿ç”¨é»˜è®¤é…ç½®åˆå§‹åŒ–DecisionTreeRegressorã€‚\n",
    "dtr = DecisionTreeRegressor()\n",
    "# ç”¨æ³¢å£«é¡¿æˆ¿ä»·çš„è®­ç»ƒæ•°æ®æ„å»ºå›å½’æ ‘ã€‚\n",
    "dtr.fit(X_train, y_train)\n",
    "# ä½¿ç”¨é»˜è®¤é…ç½®çš„å•ä¸€å›å½’æ ‘å¯¹æµ‹è¯•æ•°æ®è¿›è¡Œé¢„æµ‹ï¼Œå¹¶å°†é¢„æµ‹å€¼å­˜å‚¨åœ¨å˜é‡dtr_y_predictä¸­ã€‚\n",
    "dtr_y_predict = dtr.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared value of DecisionTreeRegressor: 0.6894984401640106\n",
      "The mean squared error of DecisionTreeRegressor: 24.07669291338583\n",
      "The mean absoluate error of DecisionTreeRegressor: 3.160629921259843\n"
     ]
    }
   ],
   "source": [
    "# ä½¿ç”¨R-squaredã€MSEä»¥åŠMAEæŒ‡æ ‡å¯¹é»˜è®¤é…ç½®çš„å›å½’æ ‘åœ¨æµ‹è¯•é›†ä¸Šè¿›è¡Œæ€§èƒ½è¯„ä¼°ã€‚\n",
    "print ('R-squared value of DecisionTreeRegressor:', dtr.score(X_test, y_test))\n",
    "print ('The mean squared error of DecisionTreeRegressor:', mean_squared_error(ss_y.inverse_transform(y_test), ss_y.inverse_transform(dtr_y_predict)))\n",
    "print ('The mean absoluate error of DecisionTreeRegressor:', mean_absolute_error(ss_y.inverse_transform(y_test), ss_y.inverse_transform(dtr_y_predict)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ç³»ç»Ÿçš„ä»‹ç»äº†å†³ç­–ï¼ˆåˆ†ç±»ï¼‰æ ‘ä¸å›å½’æ ‘ä¹‹åï¼Œå¯ä»¥æ€»ç»“è¿™ç±»æ ‘æ¨¡å‹çš„**ä¼˜ç‚¹ï¼š**\n",
    "1. æ ‘æ¨¡å‹å¯ä»¥è§£å†³éçº¿æ€§ç‰¹å¾çš„é—®é¢˜ï¼›\n",
    "2. æ ‘æ¨¡å‹ä¸è¦æ±‚å¯¹ç‰¹å¾æ ‡å‡†åŒ–å’Œç»Ÿä¸€é‡åŒ–ï¼Œå³æ•°å€¼å‹å’Œç±»åˆ«å‹ç‰¹å¾éƒ½å¯ä»¥ç›´æ¥è¢«åº”ç”¨åœ¨æ ‘æ¨¡å‹çš„æ„å»ºå’Œé¢„æµ‹è¿‡ç¨‹ä¸­ï¼›\n",
    "3. å› ä¸ºä¸Šè¿°åŸå› ï¼Œæ ‘æ¨¡å‹ä¹Ÿå¯ä»¥ç›´è§‚åœ°è¾“å‡ºå†³ç­–è¿‡ç¨‹ï¼Œä½¿å¾—é¢„æµ‹ç»“æœå…·æœ‰å¯è§£é‡Šæ€§ã€‚\n",
    "* **åŒæ—¶ï¼Œæ ‘æ¨¡å‹ä¹Ÿæœ‰ä¸€äº›æ˜¾è‘—çš„ç¼ºé™·ï¼š**\n",
    "1. æ­£æ˜¯å› ä¸ºæ ‘æ¨¡å‹å¯ä»¥è§£å†³å¤æ‚çš„éçº¿æ€§æ‹Ÿåˆé—®é¢˜ï¼Œæ‰€ä»¥æ›´åŠ å®¹æ˜“å› ä¸ºæ¨¡å‹æ­å»ºè¿‡äºå¤æ‚è€Œä¸§å¤±å¯¹æ–°æ•°æ®é¢„æµ‹çš„ç²¾åº¦ï¼ˆæ³›åŒ–åŠ›ï¼‰ï¼›\n",
    "2. æ ‘æ¨¡å‹ä»ä¸Šè‡³ä¸‹çš„é¢„æµ‹æµç¨‹ä¼šå› ä¸ºæ•°æ®ç»†å¾®çš„æ›´æ”¹è€Œå‘ç”Ÿè¾ƒå¤§çš„ç»“æ„å˜åŒ–ï¼Œå› æ­¤é¢„æµ‹ç¨³å®šæƒ³è¾ƒå·®ï¼›\n",
    "3. ä¾æ‰˜è®­ç»ƒæ•°æ®æ„å»ºæœ€ä½³æ ‘æ¨¡å‹æ˜¯NPéš¾é—®é¢˜ï¼Œå³åœ¨æœ‰é™æ—¶é—´å†…æ— æ³•æ‰¾åˆ°æœ€ä¼˜è§£çš„é—®é¢˜ï¼Œå› æ­¤æˆ‘ä»¬æ‰€ä½¿ç”¨ç±»ä¼¼è´ªå©ªç®—æ³•çš„è§£æ³•åªèƒ½æ‰¾åˆ°ä¸€äº›æ¬¡ä¼˜è§£ï¼Œè¿™ä¹Ÿæ˜¯ä¸ºä»€ä¹ˆæˆ‘ä»¬ç»å¸¸ç»“æŸé›†æˆæ¨¡å‹ï¼Œåœ¨å¤šä¸ªæ¬¡ä¼˜è§£ä¸­å¯»è§…æ›´é«˜çš„æ¨¡å‹æ€§èƒ½ã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## é›†æˆæ¨¡å‹ï¼ˆå›å½’ï¼‰\n",
    "* æç«¯éšæœºæ£®æ—ï¼ˆEextremely Randomized Treesï¼‰ ä¸æ™®é€šéšæœºæ£®æ—æ¨¡å‹ä¸åŒçš„æ˜¯ï¼Œæç«¯éšæœºæ£®æ—åœ¨æ¯å½“æ„å»ºä¸€æ£µæ ‘çš„åˆ†è£‚èŠ‚ç‚¹ï¼ˆnodeï¼‰çš„æ—¶å€™ï¼Œä¸ä¼šä»»æ„åœ°é€‰å–ç‰¹å¾ï¼Œè€Œæ˜¯å…ˆéšæœºæ‰‹æœºä¸€éƒ¨åˆ†ç‰¹å¾ï¼Œç„¶ååˆ©ç”¨ä¿¡æ¯ç†µï¼ˆinformation gainï¼‰ å’ŒåŸºå°¼ä¸çº¯æ€§ï¼ˆGini Impurity)ç­‰æŒ‡æ ‡æŒ‘é€‰æœ€ä½³çš„èŠ‚ç‚¹ç‰¹å¾ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lipengyuan/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/lipengyuan/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n",
      "/Users/lipengyuan/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/lipengyuan/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:11: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/Users/lipengyuan/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# ä»sklearn.ensembleä¸­å¯¼å…¥RandomForestRegressorã€ExtraTreesGressorä»¥åŠGradientBoostingRegressorã€‚\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, GradientBoostingRegressor\n",
    "\n",
    "# ä½¿ç”¨RandomForestRegressorè®­ç»ƒæ¨¡å‹ï¼Œå¹¶å¯¹æµ‹è¯•æ•°æ®åšå‡ºé¢„æµ‹ï¼Œç»“æœå­˜å‚¨åœ¨å˜é‡rfr_y_predictä¸­ã€‚\n",
    "rfr = RandomForestRegressor()\n",
    "rfr.fit(X_train, y_train)\n",
    "rfr_y_predict = rfr.predict(X_test)\n",
    "\n",
    "# ä½¿ç”¨ExtraTreesRegressorè®­ç»ƒæ¨¡å‹ï¼Œå¹¶å¯¹æµ‹è¯•æ•°æ®åšå‡ºé¢„æµ‹ï¼Œç»“æœå­˜å‚¨åœ¨å˜é‡etr_y_predictä¸­ã€‚\n",
    "etr = ExtraTreesRegressor()\n",
    "etr.fit(X_train, y_train)\n",
    "etr_y_predict = etr.predict(X_test)\n",
    "\n",
    "# ä½¿ç”¨GradientBoostingRegressorè®­ç»ƒæ¨¡å‹ï¼Œå¹¶å¯¹æµ‹è¯•æ•°æ®åšå‡ºé¢„æµ‹ï¼Œç»“æœå­˜å‚¨åœ¨å˜é‡gbr_y_predictä¸­ã€‚\n",
    "gbr = GradientBoostingRegressor()\n",
    "gbr.fit(X_train, y_train)\n",
    "gbr_y_predict = gbr.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared value of RandomForestRegressor: 0.7904039225449876\n",
      "The mean squared error of RandomForestRegressor: 16.252351181102362\n",
      "The mean absoluate error of RandomForestRegressor: 2.427401574803149\n"
     ]
    }
   ],
   "source": [
    "# ä½¿ç”¨R-squaredã€MSEä»¥åŠMAEæŒ‡æ ‡å¯¹é»˜è®¤é…ç½®çš„éšæœºå›å½’æ£®æ—åœ¨æµ‹è¯•é›†ä¸Šè¿›è¡Œæ€§èƒ½è¯„ä¼°ã€‚\n",
    "print ('R-squared value of RandomForestRegressor:', rfr.score(X_test, y_test))\n",
    "print ('The mean squared error of RandomForestRegressor:', mean_squared_error(ss_y.inverse_transform(y_test), ss_y.inverse_transform(rfr_y_predict)))\n",
    "print ('The mean absoluate error of RandomForestRegressor:', mean_absolute_error(ss_y.inverse_transform(y_test), ss_y.inverse_transform(rfr_y_predict)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared value of ExtraTreesRegressor: 0.8237325190594427\n",
      "The mean squared error of  ExtraTreesRegessor: 13.668008661417323\n",
      "The mean absoluate error of ExtraTreesRegessor: 2.3737795275590554\n",
      "{(0.05950056111756904, 'INDUS'), (0.03608112426859637, 'TAX'), (0.3041872533259853, 'LSTAT'), (0.04372876118169809, 'NOX'), (0.015833329972827086, 'CHAS'), (0.019750503274310577, 'PTRATIO'), (0.02074390785570981, 'CRIM'), (0.01217830614762584, 'RAD'), (0.03550605742418185, 'DIS'), (0.4196553958498484, 'RM'), (0.01479100178223286, 'AGE'), (0.0027600352520164013, 'ZN'), (0.01528376254739847, 'B')}\n"
     ]
    }
   ],
   "source": [
    "# ä½¿ç”¨R-squaredã€MSEä»¥åŠMAEæŒ‡æ ‡å¯¹é»˜è®¤é…ç½®çš„æç«¯å›å½’æ£®æ—åœ¨æµ‹è¯•é›†ä¸Šè¿›è¡Œæ€§èƒ½è¯„ä¼°ã€‚\n",
    "print ('R-squared value of ExtraTreesRegressor:', etr.score(X_test, y_test))\n",
    "print ('The mean squared error of  ExtraTreesRegessor:', mean_squared_error(ss_y.inverse_transform(y_test), ss_y.inverse_transform(etr_y_predict)))\n",
    "print ('The mean absoluate error of ExtraTreesRegessor:', mean_absolute_error(ss_y.inverse_transform(y_test), ss_y.inverse_transform(etr_y_predict)))\n",
    "\n",
    "# åˆ©ç”¨è®­ç»ƒå¥½çš„æç«¯å›å½’æ£®æ—æ¨¡å‹ï¼Œè¾“å‡ºæ¯ç§ç‰¹å¾å¯¹é¢„æµ‹ç›®æ ‡çš„è´¡çŒ®åº¦ã€‚\n",
    "\n",
    "print (set(zip(etr.feature_importances_ , boston.feature_names)))\n",
    "# print (np.array(etr.feature_importances_ , boston.feature_names))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared value of GradientBoostingRegressor: 0.828755989313912\n",
      "The mean squared error of GradientBoostingRegressor: 13.27848227468911\n",
      "The mean absoluate error of GradientBoostingRegressor: 2.3076587315993566\n"
     ]
    }
   ],
   "source": [
    "# ä½¿ç”¨R-squaredã€MSEä»¥åŠMAEæŒ‡æ ‡å¯¹é»˜è®¤é…ç½®çš„æ¢¯åº¦æå‡å›å½’æ ‘åœ¨æµ‹è¯•é›†ä¸Šè¿›è¡Œæ€§èƒ½è¯„ä¼°ã€‚\n",
    "print ('R-squared value of GradientBoostingRegressor:', gbr.score(X_test, y_test))\n",
    "print ('The mean squared error of GradientBoostingRegressor:', mean_squared_error(ss_y.inverse_transform(y_test), ss_y.inverse_transform(gbr_y_predict)))\n",
    "print ('The mean absoluate error of GradientBoostingRegressor:', mean_absolute_error(ss_y.inverse_transform(y_test), ss_y.inverse_transform(gbr_y_predict)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### å¤šç§ç»å…¸å›å½’æ¨¡å‹åœ¨â€œç¾å›½æ³¢å£«é¡¿æˆ¿ä»·é¢„æµ‹â€é—®é¢˜çš„å›å½’é¢„æµ‹èƒ½åŠ›æ’å\n",
    "* GradientBoostingRegressor\n",
    "* ExtraTreesRegressor\n",
    "* RandomForestRegressor\n",
    "* SVM Regressor ï¼ˆRBF Kernelï¼‰\n",
    "* KNN Regressor ï¼ˆDistance-weightedï¼‰\n",
    "* DecisionTreeRegressor\n",
    "* KNN Regressorï¼ˆUniform-weightedï¼‰\n",
    "* LinearRegressor\n",
    "* SGDRegressor\n",
    "* SVM Regressor ï¼ˆLinear Kernelï¼‰\n",
    "* SVM Regressor ï¼ˆPoly Kernelï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
